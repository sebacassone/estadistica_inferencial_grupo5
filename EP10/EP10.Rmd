---
title: "EP10"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(psych)
library(car)
library(ggplot2)
library(dplyr)
library(tidyr)
```

Comenzamos leyendo el archivo.
```{r}
# Leer los datos
nombre_archivo <- "EP09 Datos.csv"
carpeta <- "/home/seba/Documentos/ejercicios_R/EI/estadistica_inferencial_grupo5/EP10"
ruta <- file.path(carpeta, nombre_archivo)
datos <- read.csv2(ruta, stringsAsFactors = TRUE)

```


```{r}
# Leer los datos
nombre_archivo <- "EP09 Datos.csv"
carpeta <- "C:/Users/josef/Downloads"
ruta <- file.path(carpeta, nombre_archivo)
datos <- read.csv2(ruta, stringsAsFactors = TRUE)
```


Luego, se calcula la columna del IMC para poder insertarlo en el dataframe.

```{r}
# Calcular el IMC
datos$IMC <- datos$Weight / ((datos$Height*1/100)^2)
# Filtrar mujeres
mujeres <- subset(datos, Gender == 0)
print(cor(mujeres))
```

Con la función cor() se obtienen las correlaciones entre variables predictoras y la variable de respuesta no aún dicotómica para determinar que variables predictoras nos podrían ayudar a predecir el IMC, con esto pudimos determinar que la variable predictora que nos podría con esta tarea es Waist Girth: 0.8707, además que con investigación que pudimos realizar (https://fundaciondelcorazon.com/prensa/notas-de-prensa/2264-medida-perimetro-abdominal-es-indicador-enfermedad-cardiovascular-mas-fiable-imc-.html) pudimos determinar que esta variable predictora nos servirá en este caso.
Además, se obtiene la variable de respuesta de tipo dicotómica y agrega al dataframe. Luego, obtenemos las muestras necesarias para resolver el problema. 

```{r}
#Ahora podemos construir un modelo de regresión logística para predecir la variable EN, de acuerdo con las siguientes instrucciones:
set.seed(1412)

# Crear la variable dicotómica EN (estado nutricional)
mujeres$EN <- ifelse(mujeres$IMC >= 23.2, 1, 0)

# Separar mujeres con "Sobrepeso" y "No sobrepeso"
mujeres_sobrepeso <- subset(mujeres, EN == 1)
mujeres_no_sobrepeso <- subset(mujeres, EN == 0)

# Seleccionar 75 mujeres de cada grupo (75 "Sobrepeso" y 75 "No sobrepeso")
muestra_sobrepeso <- mujeres_sobrepeso[sample(nrow(mujeres_sobrepeso), 75), ]
muestra_no_sobrepeso <- mujeres_no_sobrepeso[sample(nrow(mujeres_no_sobrepeso), 75), ]

# Dividir la muestra en dos conjuntos
# 100 personas (50 con EN "Sobrepeso" y 50 con EN "No sobrepeso") para el modelo RLO
entrenamiento <- rbind(
  muestra_sobrepeso[1:50, ],
  muestra_no_sobrepeso[1:50, ]
)

# 50 personas (25 con EN "Sobrepeso" y 25 con EN "No sobrepeso") para la evaluación
evaluacion <- rbind(
  muestra_sobrepeso[51:75, ],
  muestra_no_sobrepeso[51:75, ]
)
```

3. Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.

- Biacromial.diameter 	Diámetro biacromial (a la altura de los hombros) 
- Biiliac.diameter 	Diámetro biiliaco (a la altura de la pelvis) 
- Bitrochanteric.diameter 	Diámetro bitrocantéreo (a la altura de las caderas) 
- Chest.depth 	Profundidad del pecho (entre la espina y el esternón a la altura de los pezones) 	cm
- Chest.diameter 	Diámetro del pecho (a la altura de los pezones)
- Elbows.diameter 	Suma de los diámetros de los codos
- Wrists.diameter 	Suma de los diámetros de las muñecas
- Knees.diameter 	Suma de los diámetros de las rodillas

4. Se construye el modelo sde regresión logística simple.

```{r}
modelo_1 <- glm(EN ~ Waist.Girth, family = binomial(link = "logit"), entrenamiento)
print(summary(modelo_1))
```

5. Se comienza a construir el modelo de regresión logística múltiple.
```{r}
modelo_nulo <- glm(EN ~ 1, family = binomial(link = "logit"), entrenamiento)
modelo_completo <- glm(EN ~ Waist.Girth + Biacromial.diameter + Biiliac.diameter + Bitrochanteric.diameter + Chest.depth + Chest.diameter + Elbows.diameter + Wrists.diameter + Knees.diameter, family = binomial(link = "logit"), entrenamiento)

# Resumen de los modelos
cat("\n\n")
cat("Modelo 1:Regresion Regresión Logística, modelo nulo\n")
cat("------------------------------------------------\n")
print(summary(modelo_nulo))


cat("\n\n")
cat("Modelo Completo:Regresion Logística Multiple - Modelo completo\n")
cat("------------------------------------------------\n")
print(summary(modelo_completo))

#Evaluar variables a incorporar
print(add1(modelo_nulo, scope = modelo_completo, test = "Chisq"))
cat("\n\n")

# Se selecciona Waight.Girth como variable predictora a incorporar dado que tiene el menor p-value.
modelo1 <- update(modelo_nulo, . ~ . + Waist.Girth)

# Luego se vuelve a evaluar una nueva variable predictora a incorporar
print(add1(modelo1, scope = modelo_completo, test = "Chisq"))

# Se elecciona la variable Chest.depth dado que tiene el menor p-value y se incorpora al modelo.
modelo2 <- update(modelo1, . ~ . + Chest.depth)
print(add1(modelo2, scope = modelo_completo, test = "Chisq"))

# Se selecciona la variable Wrists.diameter dado que tiene el menor p-value y se incorpora al modelo.
modelo3 <- update(modelo2, . ~ . + Wrists.diameter)
print(add1(modelo3, scope = modelo_completo, test = "Chisq"))

# Se selecciona la variable Knees.diameter dado que tiene el menor p-value y se incorpora al modelo.
modelo4 <- update(modelo3, . ~ . + Knees.diameter)
print(add1(modelo4, scope = modelo_completo, test = "Chisq"))

cat("Modelo final RLM")
print(summary(modelo4))
```

Luego comparamos entre ellos los modelos utilizando anova.
```{r}
resultado <- anova(modelo_nulo, modelo1, modelo2, modelo3, modelo4, modelo_completo, test = "LRT")
print(resultado)
```
Con esto obtenemos que el modelo final es significativo con un p-value = 0.031947 con un 95% de confiaza. Podemos observar que del último modelo al completo no es significativo dado que es mayor a la significancia obtenida de un 95% de confianza siendo mayor a 0,05.


El nivel de ajuste se comprobo en cada iteración analizando el p-value y AIC, ahora continuamos con la generalidad del modelo.
```{r}
#Generalidad

#Reducir a matriz de datos que solo contenga los predictores
predictores = names(coef(modelo4)) [-1]
entrenamiento = mujeres[,c(predictores, "EN")]

#Construir una matriz de datos con la respuesta predicha, los residuos y estadisiticas
#para evaluar la influencia de cada una de las 70 observaciones

resultados = data.frame(respuesta_predicha = fitted(modelo4))
resultados[["residuos_estandarizados"]] = rstandard(modelo4)
resultados[["residuos_estudiantizados"]] = rstudent(modelo4)
resultados[["distancia_Cook"]] = cooks.distance(modelo4)
resultados[["dfbeta"]] = dfbeta(modelo4)
resultados[["dffit"]] = dffits(modelo4)
resultados[["apalancamiento"]] = hatvalues(modelo4)
resultados[["covratio"]] = covratio(modelo4)


cat("Identificacion de valores atipicos : \n")
#Observaciones por fuera del 95% esperado

sospechosos1 <- which (abs (resultados [["residuos_estandarizados"]]) > 1.96)

cat("- Residuos estandarizados fuera del 95% esperado:", sospechosos1, "\n")

# Observaciones con distancia de Cook mayor a uno.
sospechosos2 <- which(resultados [["cooks.distance"]]> 1)

cat("- Residuos con una distancia de Cook alta:", sospechosos2, "\n")
# Observaciones con apalancamiento mayor igual al doble del # apalancamiento promedio.
apal_medio <- (ncol(mujeres) + 1) / nrow(mujeres)


sospechosos3 <- which (resultados [["apalancamiento"]] > 2 * apal_medio)
cat ("Residuos con apalancamiento fuera de rango:",sospechosos3, "\n")

# Observaciones con DFBeta mayor o igual a 1.
sospechosos4 <- which(apply(resultados [["dfbeta"]] >= 1, 1, any)) 
names (sospechosos4) <- NULL
cat("Residuos con DFBeta >= 1: ",sospechosos4, "\n")

# Observaciones con razón de covarianza fuera de rango. 
inferior <- 1 - 3 * apal_medio
superior <- 1 + 3 * apal_medio
sospechosos5 <- which (resultados [["covratio"]] < inferior |
                         resultados [["covratio"]]> superior)
cat("- Residuos con razón de covarianza fuera de rango: ", sospechosos5, "\n")


#Resumen de valores sospechosos.
sospechosos <- c(sospechosos1, sospechosos2, sospechosos3, sospechosos4, sospechosos5)
sospechosos <- sort (unique (sospechosos))
cat ("\nResumen de valores sospechosos: \n")
cat ("Apalancamiento promedio: ", apal_medio, "\n")

cat("Intervalo razón de covarianza: [", inferior, superior, "]\n\n", sep = "")
print(round(resultados [sospechosos, c("distancia_Cook", "apalancamiento","covratio")], 3))

cat("En el analisis de Generalidad se revisan las siguientes estadísticas de influencia como la distancia de Cook, el DFBeta y las estadísticas de apalancamiento \n1. La distancia de Cook no hay ninguna observacion que sea mayor o igual a 1. \n2.Se presentan 8 obseraciones son DFbeta mayor a 1 (14 24 47 50 67 83 87 96 ) \n3.En apalancamiento solo hay 2 observaciones fuera del rango (34 y 47)")

cat("Al eliminar las observaciones identidicas, se procovaa un sobreajuste del modelo afectando a las observaciones restantes. Esto podría causar que cualquier pequeña variabilidad en los datos tenga un impacto mayor en el modelo, por lo cual se mantiene el modelo 4. (Al intentar borrar observaciones y probar el modelo generaba mas datos problematicos)")
```

Evaluación del poder predictivo
```{r}
# Realizar predicciones sobre el conjunto de evaluación
probabilidades <- predict(modelo4, newdata = evaluacion, type = "response")

# Convertir las probabilidades en predicciones binarias utilizando un umbral de 0.5
predicciones <- ifelse(probabilidades >= 0.5, 1, 0)

# Crear una matriz de confusión
matriz_confusion <- table(Predicción = predicciones, Realidad = evaluacion$EN)
print(matriz_confusion)

# Calcular Sensibilidad
sensibilidad <- matriz_confusion[2, 2] / sum(matriz_confusion[, 2])
cat("Sensibilidad: ", round(sensibilidad, 3), "\n")

# Calcular Especificidad
especificidad <- matriz_confusion[1, 1] / sum(matriz_confusion[, 1])
cat("Especificidad: ", round(especificidad, 3), "\n")


cat("El modelo es capaz de identificar correctamente el 92% de las personas con sobrepeso (verdaderos positivos) y El modelo identifica correctamente el 84% de las personas sin sobrepeso (verdaderos negativos). Ambos valores son altos lo que indica respectivamente que el modelo es efectivo en detectar observaciones pertencientes a la clase positiva como a la clase negativa. ")
```



Ahora, se evalua las condiciones para que el modelo obtenido del paso anterior es válido como regresión lineal múltiple.

```{r}
#Condiciones
# Verificar linealidad con los predictores



#2. los residuos deben ser independientes entre si
# Verificar independencia de los residuos
cat("\nVerificación de independencia de los residuos\n")
cat("--------------------------------------------------\n")
print(durbinWatsonTest(modelo4))

```


---
title: "EP10"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Comenzamos leyendo el archivo.
```{r}
# Leer los datos
nombre_archivo <- "EP09 Datos.csv"
carpeta <- "/home/seba/Documentos/ejercicios_R/EI/estadistica_inferencial_grupo5/EP10"
ruta <- file.path(carpeta, nombre_archivo)
datos <- read.csv2(ruta, stringsAsFactors = TRUE)

```

Luego, se calcula la columna del IMC para poder insertarlo en el dataframe.

```{r}
# Calcular el IMC
datos$IMC <- datos$Weight / ((datos$Height*1/100)^2)
# Filtrar mujeres
mujeres <- subset(datos, Gender == 0)
print(cor(mujeres))
```

Con la función cor() se obtienen las correlaciones entre variables predictoras y la variable de respuesta no aún dicotómica para determinar que variables predictoras nos podrían ayudar a predecir el IMC, con esto pudimos determinar que la variable predictora que nos podría con esta tarea es Waist Girth: 0.8707, además que con investigación que pudimos realizar (https://fundaciondelcorazon.com/prensa/notas-de-prensa/2264-medida-perimetro-abdominal-es-indicador-enfermedad-cardiovascular-mas-fiable-imc-.html) pudimos determinar que esta variable predictora nos servirá en este caso.
Además, se obtiene la variable de respuesta de tipo dicotómica y agrega al dataframe. Luego, obtenemos las muestras necesarias para resolver el problema. 

```{r}
#Ahora podemos construir un modelo de regresión logística para predecir la variable EN, de acuerdo con las siguientes instrucciones:
set.seed(1412)

# Crear la variable dicotómica EN (estado nutricional)
mujeres$EN <- ifelse(mujeres$IMC >= 23.2, 1, 0)

# Separar mujeres con "Sobrepeso" y "No sobrepeso"
mujeres_sobrepeso <- subset(mujeres, EN == 1)
mujeres_no_sobrepeso <- subset(mujeres, EN == 0)

# Seleccionar 75 mujeres de cada grupo (75 "Sobrepeso" y 75 "No sobrepeso")
muestra_sobrepeso <- mujeres_sobrepeso[sample(nrow(mujeres_sobrepeso), 75), ]
muestra_no_sobrepeso <- mujeres_no_sobrepeso[sample(nrow(mujeres_no_sobrepeso), 75), ]

# Dividir la muestra en dos conjuntos
# 100 personas (50 con EN "Sobrepeso" y 50 con EN "No sobrepeso") para el modelo RLO
entrenamiento <- rbind(
  muestra_sobrepeso[1:50, ],
  muestra_no_sobrepeso[1:50, ]
)

# 50 personas (25 con EN "Sobrepeso" y 25 con EN "No sobrepeso") para la evaluación
evaluacion <- rbind(
  muestra_sobrepeso[51:75, ],
  muestra_no_sobrepeso[51:75, ]
)
```

3. Recordar las ocho posibles variables predictoras seleccionadas de forma aleatoria en el ejercicio anterior.

- Biacromial.diameter 	Diámetro biacromial (a la altura de los hombros) 
- Biiliac.diameter 	Diámetro biiliaco (a la altura de la pelvis) 
- Bitrochanteric.diameter 	Diámetro bitrocantéreo (a la altura de las caderas) 
- Chest.depth 	Profundidad del pecho (entre la espina y el esternón a la altura de los pezones) 	cm
- Chest.diameter 	Diámetro del pecho (a la altura de los pezones)
- Elbows.diameter 	Suma de los diámetros de los codos
- Wrists.diameter 	Suma de los diámetros de las muñecas
- Knees.diameter 	Suma de los diámetros de las rodillas

4. Se construye el modelo sde regresión logística simple.

```{r}
modelo_1 <- glm(EN ~ Waist.Girth, family = binomial(link = "logit"), entrenamiento)
print(summary(modelo_1))
```

5. Se comienza a construir el modelo de regresión logística múltiple.
```{r}
modelo_nulo <- glm(EN ~ 1, family = binomial(link = "logit"), entrenamiento)
modelo_completo <- glm(EN ~ Waist.Girth + Biacromial.diameter + Biiliac.diameter + Bitrochanteric.diameter + Chest.depth + Chest.diameter + Elbows.diameter + Wrists.diameter + Knees.diameter, family = binomial(link = "logit"), entrenamiento)

# Resumen de los modelos
cat("\n\n")
cat("Modelo 1:Regresion Regresión Logística, modelo nulo\n")
cat("------------------------------------------------\n")
print(summary(modelo_nulo))


cat("\n\n")
cat("Modelo Completo:Regresion Logística Multiple - Modelo completo\n")
cat("------------------------------------------------\n")
print(summary(modelo_completo))

#Evaluar variables a incorporar
print(add1(modelo_nulo, scope = modelo_completo, test = "Chisq"))
cat("\n\n")

# Se selecciona Waight.Girth como variable predictora a incorporar dado que tiene el menor p-value.
modelo1 <- update(modelo_nulo, . ~ . + Waist.Girth)

# Luego se vuelve a evaluar una nueva variable predictora a incorporar
print(add1(modelo1, scope = modelo_completo, test = "Chisq"))

# Se elecciona la variable Chest.depth dado que tiene el menor p-value y se incorpora al modelo.
modelo2 <- update(modelo1, . ~ . + Chest.depth)
print(add1(modelo2, scope = modelo_completo, test = "Chisq"))

# Se selecciona la variable Wrists.diameter dado que tiene el menor p-value y se incorpora al modelo.
modelo3 <- update(modelo2, . ~ . + Wrists.diameter)
print(add1(modelo3, scope = modelo_completo, test = "Chisq"))

# Se selecciona la variable Knees.diameter dado que tiene el menor p-value y se incorpora al modelo.
modelo4 <- update(modelo3, . ~ . + Knees.diameter)
print(add1(modelo4, scope = modelo_completo, test = "Chisq"))

cat("Modelo final RLM")
print(summary(modelo4))
```

Luego comparamos entre ellos los modelos utilizando anova.
```{r}
resultado <- anova(modelo_nulo, modelo1, modelo2, modelo3, modelo4, modelo_completo)
print(resultado)
```
Con esto obtenemos que el modelo final es significativo con un p-value = 0.031947 con un 95% de confiaza. Podemos observar que del último modelo al completo no es significativo dado que es mayor a la significancia obtenida de un 95% de confianza siendo mayor a 0,05.

Ahora, se evalua las condiciones para que el modelo obtenido del paso anterior es válido como regresión lineal múltiple.

```{r}

```

